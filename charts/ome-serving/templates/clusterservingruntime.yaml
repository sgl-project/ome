{{/*
  ClusterServingRuntime template for model inference serving.
  Currently supports sglang runtime. vLLM support coming soon.
*/}}
{{- $registry := include "ome-serving.modelRegistry" . | fromYaml }}
{{- range $modelName, $model := .Values.models }}
{{- if and $model.enabled (ne $model.createRuntime false) }}
{{- $modelInfo := index $registry $modelName }}
{{- if not $modelInfo }}
{{- fail (printf "Model '%s' not found in registry. Please check the model name or add it to the registry in _helpers.tpl" $modelName) }}
{{- end }}
{{- $gpus := $model.runtime.gpus | default 1 | int }}
{{- $preset := index $.Values.gpuPresets (printf "%d" $gpus) }}
{{- $isPdMode := $model.pdMode | default false }}
{{- $ibDevice := $model.runtime.ibDevice | default $.Values.defaults.ibDevice | default "mlx5_0" }}
{{- $rdmaProfile := $model.runtime.rdmaProfile | default $.Values.defaults.rdmaProfile | default "oci-roce" }}
---
apiVersion: ome.io/v1beta1
kind: ClusterServingRuntime
metadata:
  name: srt-{{ $modelName }}
  labels:
    {{- include "ome-serving.labels" $ | nindent 4 }}
spec:
  disabled: false
  supportedModelFormats:
    - modelFramework:
        name: transformers
        version: {{ $modelInfo.transformersVersion | quote }}
      modelFormat:
        name: safetensors
        version: "1.0.0"
      modelArchitecture: {{ $modelInfo.architecture }}
      autoSelect: {{ $modelInfo.autoSelect }}
      priority: {{ $modelInfo.priority }}
  protocolVersions:
    - openAI
  modelSizeRange:
    min: {{ index $modelInfo.sizeRange 0 }}
    max: {{ index $modelInfo.sizeRange 1 }}
  engineConfig:
    annotations:
{{- if $isPdMode }}
      rdma.ome.io/auto-inject: "true"
      rdma.ome.io/profile: {{ $rdmaProfile | quote }}
      rdma.ome.io/container-name: "ome-container"
{{- end }}
      prometheus.io/scrape: "true"
      prometheus.io/port: "8080"
      prometheus.io/path: "/metrics"
    labels:
      logging-forward: enabled
    tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
    volumes:
      - name: dshm
        emptyDir:
          medium: Memory
{{- if $isPdMode }}
    dnsPolicy: ClusterFirstWithHostNet
    hostNetwork: true
{{- end }}
    runner:
      name: ome-container
      image: {{ $model.runtime.image | default $.Values.defaults.image }}
      ports:
        - containerPort: 8080
          name: http1
          protocol: TCP
      command:
        - python3
        - -m
        - sglang.launch_server
        - --host
        - "0.0.0.0"
        - --port
        - "8080"
        - --enable-metrics
        - --model-path
        - $(MODEL_PATH)
        - --tp-size
        - "{{ $gpus }}"
        - --mem-frac
        - "{{ $model.runtime.memFrac | default $.Values.defaults.memFrac }}"
        - --served-model-name
        - {{ $modelInfo.servedName }}
{{- if $isPdMode }}
        - --disaggregation-mode
        - prefill
        - --disaggregation-ib-device
        - {{ $ibDevice }}
{{- end }}
        {{- with $model.runtime.extraArgs }}
        {{- range . }}
        - {{ . | quote }}
        {{- end }}
        {{- end }}
      volumeMounts:
        - mountPath: /dev/shm
          name: dshm
      resources:
        requests:
          cpu: {{ $preset.cpu }}
          memory: {{ $preset.memory }}
          nvidia.com/gpu: {{ $gpus }}
        limits:
          cpu: {{ $preset.cpu }}
          memory: {{ $preset.memory }}
          nvidia.com/gpu: {{ $gpus }}
      readinessProbe:
        httpGet:
{{- if $isPdMode }}
          path: /health
{{- else }}
          path: /health_generate
{{- end }}
          port: 8080
        failureThreshold: 3
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 200
      livenessProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 60
      startupProbe:
        httpGet:
{{- if $isPdMode }}
          path: /health
{{- else }}
          path: /health_generate
{{- end }}
          port: 8080
        failureThreshold: 150
        successThreshold: 1
        periodSeconds: 6
        initialDelaySeconds: 60
        timeoutSeconds: 30
{{- if $isPdMode }}
  decoderConfig:
    annotations:
      rdma.ome.io/auto-inject: "true"
      rdma.ome.io/profile: {{ $rdmaProfile | quote }}
      rdma.ome.io/container-name: "ome-container"
      prometheus.io/scrape: "true"
      prometheus.io/port: "8080"
      prometheus.io/path: "/metrics"
    labels:
      logging-forward: enabled
    tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
    volumes:
      - name: dshm
        emptyDir:
          medium: Memory
    dnsPolicy: ClusterFirstWithHostNet
    hostNetwork: true
    runner:
      name: ome-container
      image: {{ $model.runtime.image | default $.Values.defaults.image }}
      ports:
        - containerPort: 8080
          name: http1
          protocol: TCP
      command:
        - python3
        - -m
        - sglang.launch_server
        - --host
        - "0.0.0.0"
        - --port
        - "8080"
        - --enable-metrics
        - --model-path
        - $(MODEL_PATH)
        - --tp-size
        - "{{ $gpus }}"
        - --mem-frac
        - "{{ $model.runtime.memFrac | default $.Values.defaults.memFrac }}"
        - --served-model-name
        - {{ $modelInfo.servedName }}
        - --disaggregation-mode
        - decode
        - --disaggregation-ib-device
        - {{ $ibDevice }}
        {{- with $model.runtime.extraArgs }}
        {{- range . }}
        - {{ . | quote }}
        {{- end }}
        {{- end }}
      volumeMounts:
        - mountPath: /dev/shm
          name: dshm
      resources:
        requests:
          cpu: {{ $preset.cpu }}
          memory: {{ $preset.memory }}
          nvidia.com/gpu: {{ $gpus }}
        limits:
          cpu: {{ $preset.cpu }}
          memory: {{ $preset.memory }}
          nvidia.com/gpu: {{ $gpus }}
      readinessProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 3
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 200
      livenessProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 60
      startupProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 150
        successThreshold: 1
        periodSeconds: 6
        initialDelaySeconds: 60
        timeoutSeconds: 30
{{- end }}
  routerConfig:
    runner:
      name: router
      image: {{ $model.runtime.routerImage | default $.Values.defaults.routerImage }}
      resources:
        limits:
          cpu: "1"
          memory: "2Gi"
      ports:
        - containerPort: 8080
          name: http
      command:
        - python3
        - -m
        - sglang_router.launch_router
        - --host
        - "0.0.0.0"
        - --port
        - "8080"
{{- if $isPdMode }}
        - --pd-disaggregation
{{- end }}
        - --service-discovery
        - --service-discovery-namespace
        - $(NAMESPACE)
        - --service-discovery-port
        - "8080"
{{- if $isPdMode }}
        - --prefill-selector
        - component=engine ome.io/inferenceservice=$(INFERENCESERVICE_NAME)
        - --decode-selector
        - component=decoder ome.io/inferenceservice=$(INFERENCESERVICE_NAME)
{{- else }}
        - --selector
        - component=engine ome.io/inferenceservice=$(INFERENCESERVICE_NAME)
{{- end }}
      env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: INFERENCESERVICE_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ome.io/inferenceservice']
      readinessProbe:
        httpGet:
          path: /readiness
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 30
        timeoutSeconds: 10
      livenessProbe:
        httpGet:
          path: /liveness
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 30
        timeoutSeconds: 10
      startupProbe:
        httpGet:
          path: /readiness
          port: 8080
        failureThreshold: 10
        successThreshold: 1
        periodSeconds: 20
        timeoutSeconds: 10
{{- end }}
{{- end }}
