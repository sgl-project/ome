{{- if index .Values "deepseek-v3" "enabled" -}}
apiVersion: ome.io/v1beta1
kind: ClusterBaseModel
metadata:
  name: deepseek-v3
  labels:
    genai-managed-base-model-v1beta1: "true"
    models.ome.io/commit-hash: "{{ index .Values "deepseek-v3" "commitHash" }}"
  annotations:
    # TODO clean up annotations after migration, which is used in MP
    models.ome.io/runtime: "srt-multi-node-deepseek-v3-rdma"
    models.ome.io/category: "LARGE"
    models.ome.io/experimental: "{{ index .Values "deepseek-v3" "isExperimental" }}"
    models.ome.io/internal: "{{ index .Values "deepseek-v3" "isInternal" }}"
    models.ome.io/lifecycle-phase: "{{ index .Values "deepseek-v3" "lifecyclePhase" }}"
spec:
  vendor: deepseek-ai
  disabled: false
  displayName: deepseek-ai.deepseek-v3
  version: "1.0.0"
  compartmentID: {{ .Values.compartmentID }}
  modelFormat:
    name: safetensors
    version: "1"
  modelFramework:
    name: transformers
    version: "4.33.1"
  modelArchitecture: DeepseekV3ForCausalLM
  modelParameterSize: 685B
  maxTokens: 163840
  additionalMetadata:
    {{- if index .Values "deepseek-v3" "singleNode" }}
    # TODO: update single node DAC shape
    dacShapeConfigs: |-
      compatibleDACShapes:
        - name: LARGE_GENERIC_2
          quotaUnit: 1
          default: true
    {{- else }}
    dacShapeConfigs: |-
      compatibleDACShapes:
        - name: LARGE_GENERIC_4
          quotaUnit: 1
          default: true
    {{- end }}
  modelCapabilities:
    - "CHAT"
  storage:
    storageUri: "oci://n/{{ .Values.osnamespace }}/b/{{ index .Values "deepseek-v3" "osBucket" }}/o/{{ index .Values "deepseek-v3" "vendor" }}/{{ index .Values "deepseek-v3" "osPrefixOverride" }}"
    path: /mnt/data/models/deepseek-ai/deepseek-v3
  modelConfiguration:
    {
      "architectures": [
        "DeepseekV3ForCausalLM"
      ],
      "attention_bias": false,
      "attention_dropout": 0.0,
      "auto_map": {
        "AutoConfig": "configuration_deepseek.DeepseekV3Config",
        "AutoModel": "modeling_deepseek.DeepseekV3Model",
        "AutoModelForCausalLM": "modeling_deepseek.DeepseekV3ForCausalLM"
      },
      "aux_loss_alpha": 0.001,
      "bos_token_id": 0,
      "eos_token_id": 1,
      "ep_size": 1,
      "first_k_dense_replace": 3,
      "hidden_act": "silu",
      "hidden_size": 7168,
      "initializer_range": 0.02,
      "intermediate_size": 18432,
      "kv_lora_rank": 512,
      "max_position_embeddings": 163840,
      "model_type": "deepseek_v3",
      "moe_intermediate_size": 2048,
      "moe_layer_freq": 1,
      "n_group": 8,
      "n_routed_experts": 256,
      "n_shared_experts": 1,
      "norm_topk_prob": true,
      "num_attention_heads": 128,
      "num_experts_per_tok": 8,
      "num_hidden_layers": 61,
      "num_key_value_heads": 128,
      "num_nextn_predict_layers": 1,
      "pretraining_tp": 1,
      "q_lora_rank": 1536,
      "qk_nope_head_dim": 128,
      "qk_rope_head_dim": 64,
      "quantization_config": {
        "activation_scheme": "dynamic",
        "fmt": "e4m3",
        "quant_method": "fp8",
        "weight_block_size": [
          128,
          128
        ]
      },
      "rms_norm_eps": 1e-06,
      "rope_scaling": {
        "beta_fast": 32,
        "beta_slow": 1,
        "factor": 40,
        "mscale": 1.0,
        "mscale_all_dim": 1.0,
        "original_max_position_embeddings": 4096,
        "type": "yarn"
      },
      "rope_theta": 10000,
      "routed_scaling_factor": 2.5,
      "scoring_func": "sigmoid",
      "seq_aux": true,
      "tie_word_embeddings": false,
      "topk_group": 4,
      "topk_method": "noaux_tc",
      "torch_dtype": "bfloat16",
      "transformers_version": "4.33.1",
      "use_cache": true,
      "v_head_dim": 128,
      "vocab_size": 129280
    }
{{- end }}