apiVersion: ome.io/v1beta1
kind: ClusterServingRuntime
metadata:
  name: gliner-large-v2-1
spec:
  annotations:
    prometheus.io/port: '8080'
    prometheus.io/scrape: 'true'
  labels:
    logging-forward: enabled
    sidecar.istio.io/inject: 'true'
  tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
  supportedModelFormats:
    - autoSelect: true
      modelFormat:
        name: pytorch
        version: "1"
      modelFramework:
        name: transformer
        version: "1"
      version: '1'
  modelSizeRange:
    min: 300M
    max: 600M
  containers:
    - name: ome-container
      image: {{ .Values.gliner_large_v2_1.image.repository }}:{{ .Values.gliner_large_v2_1.image.tag }}
      env:
        - name: HF_HOME
          value: /model/gliner-large-v2-1
      ports:
        - containerPort: 8080
          name: http
          protocol: TCP
      resources:
        requests:
          cpu: 16
          memory: 60Gi
      readinessProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 3
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 60
      livenessProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 60
      startupProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 150
        successThreshold: 1
        periodSeconds: 6
        initialDelaySeconds: 60
        timeoutSeconds: 30