apiVersion: ome.io/v1beta1
kind: TrainingJob
metadata:
  name: "ft-llama-3-3-70b-instruct"
  namespace: "dac-training-test"
spec:
  runtimeRef:
    name: llama-3-3-70b-instruct-ft
  trainer: {}
  modelConfig:
    inputModel: llama-3-3-70b-instruct-ft
  datasets:
    storageUri: oci://n/idqj093njucb/b/beiwen_test/o/sales_pitch_generation_train.jsonl
  hyperParameterTuningConfig:
    method: "bayes"
    metric:
      name: hyperparameter-metric
      goal: maximize
    parameters:
      {
        "strategy": "lora",
        "trainingBatchSize": "8",
        "totalTrainingEpochs": "3",
        "earlyStoppingPatience": "15",
        "earlyStoppingThreshold": "0.0001",
        "learningRate": "0.0002",
        "logModelMetricsIntervalInSteps": "10",
        "loraR": "8",
        "loraAlpha": "8",
        "loraDropout": "0.1"
      }