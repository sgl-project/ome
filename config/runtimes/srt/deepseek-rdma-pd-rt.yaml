apiVersion: ome.io/v1beta1
kind: ClusterServingRuntime
metadata:
  name: srt-deepseek-rdma-pd
spec:
  disabled: false
  modelSizeRange:
    min: 650B
    max: 700B
  supportedModelFormats:
    - modelFormat:
        name: safetensors
        version: "1.0.0"
        operator: GreaterThanOrEqual
      version: "1.0.0"
      modelFramework:
        name: transformers
        version: "4.33.1"
        operator: GreaterThanOrEqual
      modelArchitecture: DeepseekV3ForCausalLM
      quantization: "fp8"
      autoSelect: false
      priority: 1
  protocolVersions:
    - openAI
  engineConfig:
    leader:
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      enableServiceLinks: false
      hostIPC: true
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - name: devinf
          hostPath:
            path: /dev/infiniband
      runner:
        name: ome-container
        image: docker.io/lmsysorg/sglang:v0.5.5.post3-cu129-amd64
        env:
          - name: MC_TE_METRIC
            value: "true"
          - name: PYTHONUNBUFFERED
            value: "1"
          - name: GLOO_SOCKET_IFNAME
            value: eth0
          - name: NODE_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: SGLANG_TBO_DEBUG
            value: "1"
          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING
            value: '1'
          - name: SGLANG_SET_CPU_AFFINITY
            value: 'true'
          - name: SGLANG_ENABLE_JIT_DEEPGEMM
            value: '0'
          - name: NVSHMEM_HCA_LIST
            value: mlx5_0:1,mlx5_1:1,mlx5_3:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_8:1,mlx5_9:1,mlx5_10:1,mlx5_12:1,mlx5_13:1,mlx5_14:1,mlx5_15:1,mlx5_16:1,mlx5_17:1
          - name: NVSHMEM_IB_GID_INDEX
            value: '3'
        command:
          - python3
          - -m
          - sglang.launch_server
          - --port
          - "30000"
          - --host
          - "0.0.0.0"
          - --model-path
          - $(MODEL_PATH)
          - --disaggregation-ib-device
          - mlx5_0,mlx5_1,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17
          - --chunked-prefill-size
          - "524288"
          - --ep-dispatch-algorithm
          - dynamic
          - --eplb-algorithm
          - deepseek
          - --enable-dp-lm-head
          - --disable-cuda-graph
          - --enable-two-batch-overlap
          - --enable-dp-attention
          - --disable-shared-experts-fusion
          - --dp-size
          - $(PARALLELISM_SIZE)
          - --disable-radix-cache
          - --moe-a2a-backend
          - deepep
          - --deepep-mode
          - normal
          - --disaggregation-mode
          - prefill
          - --mem-fraction-static
          - "0.849"
          - --tp-size
          - $(PARALLELISM_SIZE)
          - --dist-init-addr
          - $(LWS_LEADER_ADDRESS):5757
          - --nnodes
          - $(LWS_GROUP_SIZE)
          - --node-rank
          - $(LWS_WORKER_INDEX)
          - --trust-remote-code
          - --served-model-name
          - deepseek-ai/DeepSeek-V3
          - --moe-dense-tp-size
          - "1"
          - --decode-log-interval
          - "1"
          - --max-total-tokens
          - "131072"
          - --enable-eplb
          - --ep-num-redundant-experts
          - $(PARALLELISM_SIZE)
          - --load-balance-method
          - round_robin
          - --watchdog-timeout
          - "1000000"
          - --page-size
          - "1"
        resources:
          requests:
            nvidia.com/gpu: 8
          limits:
            nvidia.com/gpu: 8
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
    worker:
      size: 1
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      enableServiceLinks: false
      hostIPC: true
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - name: devinf
          hostPath:
            path: /dev/infiniband
      runner:
        name: ome-container
        image: docker.io/lmsysorg/sglang:v0.5.5.post3-cu129-amd64
        env:
          - name: MC_TE_METRIC
            value: "true"
          - name: PYTHONUNBUFFERED
            value: "1"
          - name: GLOO_SOCKET_IFNAME
            value: eth0
          - name: NODE_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: SGLANG_SET_CPU_AFFINITY
            value: 'true'
          - name: SGLANG_HACK_DEEPEP_NUM_SMS
            value: '8'
          - name: SGLANG_HACK_DEEPEP_NEW_MODE
            value: '0'
          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING
            value: '1'
          - name: SGLANG_MOONCAKE_TRANS_THREAD
            value: '8'
          - name: SGLANG_ENABLE_JIT_DEEPGEMM
            value: '0'
          - name: SGLANG_CHUNKED_PREFIX_CACHE_THRESHOLD
            value: '0'
          - name: NVSHMEM_HCA_LIST
            value: mlx5_0:1,mlx5_1:1,mlx5_3:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_8:1,mlx5_9:1,mlx5_10:1,mlx5_12:1,mlx5_13:1,mlx5_14:1,mlx5_15:1,mlx5_16:1,mlx5_17:1
          - name: NVSHMEM_IB_GID_INDEX
            value: '3'
        command:
          - python3
          - -m
          - sglang.launch_server
          - --model-path
          - $(MODEL_PATH)
          - --disaggregation-ib-device
          - mlx5_0,mlx5_1,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17
          - --chunked-prefill-size
          - "524288"
          - --ep-dispatch-algorithm
          - dynamic
          - --eplb-algorithm
          - deepseek
          - --enable-dp-lm-head
          - --disable-cuda-graph
          - --enable-two-batch-overlap
          - --enable-dp-attention
          - --disable-shared-experts-fusion
          - --dp-size
          - $(PARALLELISM_SIZE)
          - --disable-radix-cache
          - --moe-a2a-backend
          - deepep
          - --deepep-mode
          - normal
          - --disaggregation-mode
          - prefill
          - --mem-fraction-static
          - "0.849"
          - --tp-size
          - $(PARALLELISM_SIZE)
          - --dist-init-addr
          - $(LWS_LEADER_ADDRESS):5757
          - --nnodes
          - $(LWS_GROUP_SIZE)
          - --node-rank
          - $(LWS_WORKER_INDEX)
          - --trust-remote-code
          - --served-model-name
          - deepseek-ai/DeepSeek-V3
          - --moe-dense-tp-size
          - "1"
          - --decode-log-interval
          - "1"
          - --max-total-tokens
          - "131072"
          - --enable-eplb
          - --ep-num-redundant-experts
          - $(PARALLELISM_SIZE)
          - --load-balance-method
          - round_robin
          - --watchdog-timeout
          - "1000000"
          - --page-size
          - "1"
        resources:
          limits:
            nvidia.com/gpu: "8"
          requests:
            nvidia.com/gpu: "8"
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
  decoderConfig:
    leader:
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - name: devinf
          hostPath:
            path: /dev/infiniband
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      enableServiceLinks: false
      hostIPC: true
      runner:
        name: ome-container
        image: docker.io/lmsysorg/sglang:v0.5.5.post3-cu129-amd64
        env:
          - name: MC_TE_METRIC
            value: "true"
          - name: PYTHONUNBUFFERED
            value: "1"
          - name: SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK
            value: "480"
          - name: GLOO_SOCKET_IFNAME
            value: eth0
          - name: NODE_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: SGLANG_MOONCAKE_TRANS_THREAD
            value: '16'
          - name: SGLANG_ENABLE_JIT_DEEPGEMM
            value: '0'
          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING
            value: '1'
          - name: NVSHMEM_HCA_LIST
            value: mlx5_0:1,mlx5_1:1,mlx5_3:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_8:1,mlx5_9:1,mlx5_10:1,mlx5_12:1,mlx5_13:1,mlx5_14:1,mlx5_15:1,mlx5_16:1,mlx5_17:1
          - name: NVSHMEM_IB_GID_INDEX
            value: '3'
        command:
          - python3
          - -m
          - sglang.launch_server
          - --port
          - "30000"
          - --host
          - "0.0.0.0"
          - --model-path
          - $(MODEL_PATH)
          - --enable-dp-attention
          - --enable-dp-lm-head
          - --dp-size
          - $(PARALLELISM_SIZE)
          - --disable-radix-cache
          - --disable-shared-experts-fusion
          - --moe-a2a-backend
          - deepep
          - --deepep-mode
          - low_latency
          - --disaggregation-mode
          - decode
          - --enable-two-batch-overlap
          - --mem-fraction-static
          - "0.835"
          - --disaggregation-ib-device
          - mlx5_0,mlx5_1,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17
          - --cuda-graph-bs
          - "128"
          - --tp-size
          - $(PARALLELISM_SIZE)
          - --dist-init-addr
          - $(LWS_LEADER_ADDRESS):5757
          - --nnodes
          - $(LWS_GROUP_SIZE)
          - --node-rank
          - $(LWS_WORKER_INDEX)
          - --decode-log-interval
          - "1"
          - --trust-remote-code
          - --served-model-name
          - deepseek-ai/DeepSeek-V3
          - --moe-dense-tp-size
          - "1"
          - --ep-num-redundant-experts
          - $(PARALLELISM_SIZE)
          - --enable-eplb
          - --prefill-round-robin-balance
          - --watchdog-timeout
          - "1000000"
          - --page-size
          - "1"
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
        resources:
          requests:
            nvidia.com/gpu: 8
          limits:
            nvidia.com/gpu: 8
    worker:
      size: 1
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      enableServiceLinks: false
      hostIPC: true
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - name: devinf
          hostPath:
            path: /dev/infiniband
      runner:
        name: ome-container
        image: docker.io/lmsysorg/sglang:v0.5.5.post3-cu129-amd64
        env:
          - name: MC_TE_METRIC
            value: "true"
          - name: PYTHONUNBUFFERED
            value: "1"
          - name: SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK
            value: "480"
          - name: GLOO_SOCKET_IFNAME
            value: eth0
          - name: NODE_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: SGLANG_HACK_DEEPEP_NUM_SMS
            value: '24'
          - name: SGLANG_HACK_DEEPEP_NEW_MODE
            value: '0'
          - name: NVSHMEM_IB_TRAFFIC_CLASS
            value: '16'
          - name: SGLANG_MOONCAKE_TRANS_THREAD
            value: '16'
          - name: SGLANG_ENABLE_JIT_DEEPGEMM
            value: '0'
          - name: NVSHMEM_ENABLE_NIC_PE_MAPPING
            value: '1'
          - name: NVSHMEM_HCA_LIST
            value: mlx5_0:1,mlx5_1:1,mlx5_3:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_8:1,mlx5_9:1,mlx5_10:1,mlx5_12:1,mlx5_13:1,mlx5_14:1,mlx5_15:1,mlx5_16:1,mlx5_17:1
          - name: NVSHMEM_IB_GID_INDEX
            value: '3'
        command:
          - python3
          - -m
          - sglang.launch_server
          - --model-path
          - $(MODEL_PATH)
          - --enable-dp-attention
          - --enable-dp-lm-head
          - --dp-size
          - $(PARALLELISM_SIZE)
          - --disable-radix-cache
          - --disable-shared-experts-fusion
          - --moe-a2a-backend
          - deepep
          - --deepep-mode
          - low_latency
          - --disaggregation-mode
          - decode
          - --enable-two-batch-overlap
          - --mem-fraction-static
          - "0.835"
          - --disaggregation-ib-device
          - mlx5_0,mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17
          - --cuda-graph-bs
          - "128"
          - --tp-size
          - $(PARALLELISM_SIZE)
          - --dist-init-addr
          - $(LWS_LEADER_ADDRESS):5757
          - --nnodes
          - $(LWS_GROUP_SIZE)
          - --node-rank
          - $(LWS_WORKER_INDEX)
          - --decode-log-interval
          - "1"
          - --trust-remote-code
          - --served-model-name
          - deepseek-ai/DeepSeek-V3
          - --moe-dense-tp-size
          - "1"
          - --ep-num-redundant-experts
          - $(PARALLELISM_SIZE)
          - --enable-eplb
          - --prefill-round-robin-balance
          - --watchdog-timeout
          - "1000000"
          - --page-size
          - "1"
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
        resources:
          limits:
            nvidia.com/gpu: "8"
          requests:
            nvidia.com/gpu: "8"
  routerConfig:
    runner:
      name: router
      image: fra.ocir.io/idqj093njucb/smg:v0.2.4.post1-dev
      resources:
        limits:
          cpu: "1"
          memory: "2Gi"
      ports:
        - containerPort: 8080
          name: http
      command:
        - sh
        - -c
        - >
          python3 -m sglang_router.launch_router
          --host 0.0.0.0
          --port 8080
          --pd-disaggregation
          --policy random
          --service-discovery
          --service-discovery-namespace "${NAMESPACE}"
          --service-discovery-port 30000
          --prefill-selector component=engine leaderworkerset.sigs.k8s.io/worker-index=0 ome.io/inferenceservice=${INFERENCESERVICE_NAME}
          --decode-selector component=decoder leaderworkerset.sigs.k8s.io/worker-index=0 ome.io/inferenceservice=${INFERENCESERVICE_NAME}
          --max-payload-size 2147483648
          --worker-startup-timeout-secs 1200
      env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: INFERENCESERVICE_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ome.io/inferenceservice']
      readinessProbe:
        httpGet:
          path: /readiness
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 30
        timeoutSeconds: 10
      livenessProbe:
        httpGet:
          path: /liveness
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 30
        timeoutSeconds: 10
      startupProbe:
        httpGet:
          path: /readiness
          port: 8080
        failureThreshold: 10
        successThreshold: 1
        periodSeconds: 20
        timeoutSeconds: 10
