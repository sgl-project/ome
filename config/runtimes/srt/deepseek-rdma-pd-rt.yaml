apiVersion: ome.io/v1beta1
kind: ClusterServingRuntime
metadata:
  name: srt-deepseek-pd-rdma
spec:
  disabled: false
  modelSizeRange:
    min: 650B
    max: 700B
  supportedModelFormats:
    - modelFormat:
        name: safetensors
        version: "1"
      version: "1.0.0"
      modelFramework:
        name: transformers
        version: "4.46.3"
      modelArchitecture: DeepseekV3ForCausalLM
      quantization: "fp8"
      autoSelect: false
      priority: 1
    - modelFormat:
        name: safetensors
        version: "1"
      version: "1.0.0"
      modelFramework:
        name: transformers
        version: "4.33.1"
      modelArchitecture: DeepseekV3ForCausalLM
      quantization: "fp8"
      autoSelect: false
      priority: 1
  protocolVersions:
    - openAI
  engineConfig:
    leader:
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      nodeSelector:
        oci.oraclecloud.com/rdma.authenticated: "16"
        oci.oraclecloud.com/rdma.mlx_issues: "0"
        oke.oraclecloud.com/pool.mode: cluster-network
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node.kubernetes.io/instance-type
                    operator: In
                    values:
                      - BM.GPU.H100.8
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - hostPath:
            path: /dev/infiniband
          name: devinf
      runner:
        name: ome-container
        image: fra.ocir.io/idqj093njucb/official-sgl:deepdev-1
        env:
          - name: NCCL_DEBUG
            value: INFO
          - name: NCCL_CROSS_NIC
            value: '2'
          - name: NCCL_SOCKET_NTHREADS
            value: '16'
          - name: NCCL_CUMEM_ENABLE
            value: '0'
          - name: NCCL_IB_SPLIT_DATA_ON_QPS
            value: '0'
          - name: NCCL_IB_QPS_PER_CONNECTION
            value: '16'
          - name: NCCL_IB_GID_INDEX
            value: '3'
          - name: NCCL_IB_HCA
            value: "mlx5_0,mlx5_1,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17"
          - name: NCCL_IB_TC
            value: '41'
          - name: NCCL_IB_SL
            value: '0'
          - name: NCCL_IB_TIMEOUT
            value: '22'
          - name: HCOLL_ENABLE_MCAST_ALL
            value: '0'
          - name: coll_hcoll_enable
            value: '0'
          - name: UCX_TLS
            value: tcp
          - name: UCX_NET_DEVICES
            value: eth0
          - name: RX_QUEUE_LEN
            value: '8192'
          - name: IB_RX_QUEUE_LEN
            value: '8192'
          - name: NCCL_SOCKET_IFNAME
            value: eth0
          - name: NCCL_IGNORE_CPU_AFFINITY
            value: '1'
          - name: GLOO_SOCKET_IFNAME
            value: eth0
        command:
          - sh
          - -c
          - >
            MC_TE_METRIC=true;
            SGLANG_TBO_DEBUG=1;
            pip install mooncake-transfer-engine --break-system-packages;
            python3 -m sglang.launch_server
            --model-path ${MODEL_PATH}
            --disaggregation-ib-device mlx5_0,mlx5_1,mlx5_3,mlx5_4
            --disaggregation-mode prefill
            --dist-init-addr $(LWS_LEADER_ADDRESS):5000
            --nnodes ${LWS_GROUP_SIZE}
            --node-rank ${LWS_WORKER_INDEX}
            --port 30000
            --tp-size ${PARALLELISM_SIZE}
            --dp-size ${PARALLELISM_SIZE}
            --enable-dp-attention
            --decode-log-interval 1
            --enable-deepep-moe
            --page-size 1
            --host 0.0.0.0
            --trust-remote-code
            --moe-dense-tp-size 1
            --enable-dp-lm-head
            --deepep-mode normal
            --mem-fraction-static 0.75
            --chunked-prefill-size 524288
            --max-running-requests 8192
            --max-total-tokens 131072
            --context-length 8192
            --ep-num-redundant-experts 32
            --ep-dispatch-algorithm dynamic
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf
        resources:
          requests:
            nvidia.com/gpu: 8
          limits:
            nvidia.com/gpu: 8
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
        readinessProbe:
          httpGet:
            path: /health_generate
            port: 8080
          failureThreshold: 3
          successThreshold: 1
          periodSeconds: 60
          timeoutSeconds: 200
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          failureThreshold: 5
          successThreshold: 1
          periodSeconds: 60
          timeoutSeconds: 60
        startupProbe:
          httpGet:
            path: /health_generate
            port: 8080
          failureThreshold: 300
          successThreshold: 1
          periodSeconds: 10
          initialDelaySeconds: 600
          timeoutSeconds: 30
    worker:
      size: 3
      nodeSelector:
        oci.oraclecloud.com/rdma.authenticated: "16"
        oci.oraclecloud.com/rdma.mlx_issues: "0"
        oke.oraclecloud.com/pool.mode: cluster-network
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node.kubernetes.io/instance-type
                    operator: In
                    values:
                      - BM.GPU.H100.8
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 15Gi
        - hostPath:
            path: /dev/infiniband
          name: devinf
      runner:
        name: ome-container
        image: fra.ocir.io/idqj093njucb/official-sgl:deepdev-1
        command:
          - sh
          - -c
          - >
            MC_TE_METRIC=true;
            SGLANG_TBO_DEBUG=1;
            pip install mooncake-transfer-engine --break-system-packages;
            python3 -m sglang.launch_server
            --model-path ${MODEL_PATH}
            --disaggregation-ib-device mlx5_0,mlx5_1,mlx5_3,mlx5_4
            --disaggregation-mode prefill
            --dist-init-addr $(LWS_LEADER_ADDRESS):5000
            --nnodes ${LWS_GROUP_SIZE}
            --node-rank ${LWS_WORKER_INDEX}
            --port 30000
            --tp-size ${PARALLELISM_SIZE}
            --dp-size ${PARALLELISM_SIZE}
            --enable-dp-attention
            --decode-log-interval 1
            --enable-deepep-moe
            --page-size 1
            --host 0.0.0.0
            --trust-remote-code
            --moe-dense-tp-size 1
            --enable-dp-lm-head
            --deepep-mode normal
            --mem-fraction-static 0.75
            --chunked-prefill-size 524288
            --max-running-requests 8192
            --max-total-tokens 131072
            --context-length 8192
            --ep-num-redundant-experts 32
            --ep-dispatch-algorithm dynamic
        resources:
          limits:
            nvidia.com/gpu: "8"
          requests:
            nvidia.com/gpu: "8"
        env:
          - name: NCCL_DEBUG
            value: INFO
          - name: NCCL_CROSS_NIC
            value: '2'
          - name: NCCL_SOCKET_NTHREADS
            value: '16'
          - name: NCCL_CUMEM_ENABLE
            value: '0'
          - name: NCCL_IB_SPLIT_DATA_ON_QPS
            value: '0'
          - name: NCCL_IB_QPS_PER_CONNECTION
            value: '16'
          - name: NCCL_IB_GID_INDEX
            value: '3'
          - name: NCCL_IB_HCA
            value: "mlx5_0,mlx5_1,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17"
          - name: NCCL_IB_TC
            value: '41'
          - name: NCCL_IB_SL
            value: '0'
          - name: NCCL_IB_TIMEOUT
            value: '22'
          - name: HCOLL_ENABLE_MCAST_ALL
            value: '0'
          - name: coll_hcoll_enable
            value: '0'
          - name: UCX_TLS
            value: tcp
          - name: UCX_NET_DEVICES
            value: eth0
          - name: RX_QUEUE_LEN
            value: '8192'
          - name: IB_RX_QUEUE_LEN
            value: '8192'
          - name: NCCL_SOCKET_IFNAME
            value: eth0
          - name: NCCL_IGNORE_CPU_AFFINITY
            value: '1'
          - name: GLOO_SOCKET_IFNAME
            value: eth0
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf
  decoderConfig:
    leader:
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      nodeSelector:
        oci.oraclecloud.com/rdma.authenticated: "16"
        oci.oraclecloud.com/rdma.mlx_issues: "0"
        oke.oraclecloud.com/pool.mode: cluster-network
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node.kubernetes.io/instance-type
                    operator: In
                    values:
                      - BM.GPU.H100.8
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - hostPath:
            path: /dev/infiniband
          name: devinf
      runner:
        name: ome-container
        image: fra.ocir.io/idqj093njucb/official-sgl:deepdev-1
        env:
          - name: NCCL_DEBUG
            value: INFO
          - name: NCCL_CROSS_NIC
            value: '2'
          - name: NCCL_SOCKET_NTHREADS
            value: '16'
          - name: NCCL_CUMEM_ENABLE
            value: '0'
          - name: NCCL_IB_SPLIT_DATA_ON_QPS
            value: '0'
          - name: NCCL_IB_QPS_PER_CONNECTION
            value: '16'
          - name: NCCL_IB_GID_INDEX
            value: '3'
          - name: NCCL_IB_HCA
            value: "mlx5_0,mlx5_1,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17"
          - name: NCCL_IB_TC
            value: '41'
          - name: NCCL_IB_SL
            value: '0'
          - name: NCCL_IB_TIMEOUT
            value: '22'
          - name: HCOLL_ENABLE_MCAST_ALL
            value: '0'
          - name: coll_hcoll_enable
            value: '0'
          - name: UCX_TLS
            value: tcp
          - name: UCX_NET_DEVICES
            value: eth0
          - name: RX_QUEUE_LEN
            value: '8192'
          - name: IB_RX_QUEUE_LEN
            value: '8192'
          - name: NCCL_SOCKET_IFNAME
            value: eth0
          - name: NCCL_IGNORE_CPU_AFFINITY
            value: '1'
          - name: GLOO_SOCKET_IFNAME
            value: eth0
        command:
          - sh
          - -c
          - >
            MC_TE_METRIC=true;
            SGLANG_TBO_DEBUG=1;
            pip install mooncake-transfer-engine --break-system-packages;
            python3 -m sglang.launch_server
            --model-path ${MODEL_PATH}
            --disaggregation-ib-device mlx5_0,mlx5_1,mlx5_3,mlx5_4
            --disaggregation-mode decode
            --base-gpu-id 0
            --dist-init-addr $(LWS_LEADER_ADDRESS):5000
            --nnodes ${LWS_GROUP_SIZE}
            --port 30001
            --node-rank ${LWS_WORKER_INDEX}
            --tp-size ${PARALLELISM_SIZE}
            --dp-size ${PARALLELISM_SIZE}
            --enable-dp-attention
            --decode-log-interval 1
            --enable-deepep-moe
            --page-size 64
            --chunked-prefill-size 6144
            --host 0.0.0.0
            --trust-remote-code
            --moe-dense-tp-size 1
            --enable-dp-lm-head
            --deepep-mode low_latency
            --mem-fraction-static 0.75
            --max-running-requests 4096
            --context-length 32768
            --ep-num-redundant-experts 32
            --cuda-graph-max-bs 128
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf
        resources:
          requests:
            nvidia.com/gpu: 8
          limits:
            nvidia.com/gpu: 8
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
        readinessProbe:
          httpGet:
            path: /health_generate
            port: 8080
          failureThreshold: 3
          successThreshold: 1
          periodSeconds: 60
          timeoutSeconds: 200
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          failureThreshold: 5
          successThreshold: 1
          periodSeconds: 60
          timeoutSeconds: 60
        startupProbe:
          httpGet:
            path: /health_generate
            port: 8080
          failureThreshold: 300
          successThreshold: 1
          periodSeconds: 10
          initialDelaySeconds: 600
          timeoutSeconds: 30
    worker:
      size: 3
      nodeSelector:
        oci.oraclecloud.com/rdma.authenticated: "16"
        oci.oraclecloud.com/rdma.mlx_issues: "0"
        oke.oraclecloud.com/pool.mode: cluster-network
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node.kubernetes.io/instance-type
                    operator: In
                    values:
                      - BM.GPU.H100.8
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 15Gi
        - hostPath:
            path: /dev/infiniband
          name: devinf
      runner:
        name: ome-container
        image: fra.ocir.io/idqj093njucb/official-sgl:deepdev-1
        command:
          - sh
          - -c
          - >
            MC_TE_METRIC=true;
            SGLANG_TBO_DEBUG=1;
            pip install mooncake-transfer-engine --break-system-packages;
            python3 -m sglang.launch_server
            --model-path ${MODEL_PATH}
            --disaggregation-ib-device mlx5_0,mlx5_1,mlx5_3,mlx5_4
            --disaggregation-mode decode
            --base-gpu-id 0
            --dist-init-addr $(LWS_LEADER_ADDRESS):5000
            --nnodes ${LWS_GROUP_SIZE}
            --node-rank ${LWS_WORKER_INDEX}
            --port 30001
            --tp-size ${PARALLELISM_SIZE}
            --dp-size ${PARALLELISM_SIZE}
            --enable-dp-attention
            --decode-log-interval 1
            --enable-deepep-moe
            --page-size 64
            --chunked-prefill-size 6144
            --host 0.0.0.0
            --trust-remote-code
            --moe-dense-tp-size 1
            --enable-dp-lm-head
            --deepep-mode low_latency
            --mem-fraction-static 0.75
            --max-running-requests 4096
            --context-length 32768
            --ep-num-redundant-experts 32
            --cuda-graph-max-bs 128
        resources:
          limits:
            nvidia.com/gpu: "8"
          requests:
            nvidia.com/gpu: "8"
        env:
          - name: NCCL_DEBUG
            value: INFO
          - name: NCCL_CROSS_NIC
            value: '2'
          - name: NCCL_SOCKET_NTHREADS
            value: '16'
          - name: NCCL_CUMEM_ENABLE
            value: '0'
          - name: NCCL_IB_SPLIT_DATA_ON_QPS
            value: '0'
          - name: NCCL_IB_QPS_PER_CONNECTION
            value: '16'
          - name: NCCL_IB_GID_INDEX
            value: '3'
          - name: NCCL_IB_HCA
            value: "mlx5_0,mlx5_1,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8,mlx5_9,mlx5_10,mlx5_12,mlx5_13,mlx5_14,mlx5_15,mlx5_16,mlx5_17"
          - name: NCCL_IB_TC
            value: '41'
          - name: NCCL_IB_SL
            value: '0'
          - name: NCCL_IB_TIMEOUT
            value: '22'
          - name: HCOLL_ENABLE_MCAST_ALL
            value: '0'
          - name: coll_hcoll_enable
            value: '0'
          - name: UCX_TLS
            value: tcp
          - name: UCX_NET_DEVICES
            value: eth0
          - name: RX_QUEUE_LEN
            value: '8192'
          - name: IB_RX_QUEUE_LEN
            value: '8192'
          - name: NCCL_SOCKET_IFNAME
            value: eth0
          - name: NCCL_IGNORE_CPU_AFFINITY
            value: '1'
          - name: GLOO_SOCKET_IFNAME
            value: eth0
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - CAP_SYS_ADMIN
          privileged: true
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /dev/infiniband
            name: devinf