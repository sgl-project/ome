apiVersion: ome.io/v1beta1
kind: ClusterServingRuntime
metadata:
  name: srt-llama-4-scout-17b-16e-instruct
spec:
  disabled: false
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
  labels:
    logging-forward: enabled
  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
  volumes:
    - name: dshm
      emptyDir:
        medium: Memory
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values:
                  - BM.GPU.H100.8
  supportedModelFormats:
    - modelFramework:
        name: transformers
        version: "4.51.0.dev0"
      modelFormat:
        name: safetensors
        version: "1"
      modelArchitecture: Llama4ForConditionalGeneration
      autoSelect: true
      priority: 2
  modelSizeRange:
    min: 100B
    max: 109B
  protocolVersions:
    - openAI
  containers:
    - name: ome-container
      image: fra.ocir.io/idqj093njucb/official-sgl:v0.4.5.5e34fb5-cu124
      ports:
        - containerPort: 8080
          name: http1
          protocol: TCP
      command:
        - /bin/bash
        - '-lc'
        - --
      args:
        - |
          python3 -m sglang.launch_server \
          --host=0.0.0.0 \
          --port=8080 \
          --enable-metrics \
          --model-path="$MODEL_PATH" \
          --tp 4 \
          --mem-frac=0.95 \
          --context-length=128000 \
          --chat-template llama-4 \
          --attention-backend fa3 \
          --log-requests
      volumeMounts:
        - mountPath: /dev/shm
          name: dshm
      resources:
        requests:
          cpu: 64
          memory: 256Gi
          nvidia.com/gpu: 4
        limits:
          cpu: 64
          memory: 256Gi
          nvidia.com/gpu: 4

      readinessProbe:
        httpGet:
          path: /health_generate
          port: 8080
        failureThreshold: 3
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 200

      livenessProbe:
        httpGet:
          path: /health
          port: 8080
        failureThreshold: 5
        successThreshold: 1
        periodSeconds: 60
        timeoutSeconds: 60

      startupProbe:
        httpGet:
          path: /health_generate
          port: 8080
        failureThreshold: 150
        successThreshold: 1
        periodSeconds: 6
        initialDelaySeconds: 60
        timeoutSeconds: 30
