apiVersion: ome.io/v1beta1
kind: ClusterBaseModel
metadata:
  name: llama-3-2-90b-vision-instruct-fp8-dynamic
  labels:
    genai-managed-base-model-v1beta1: "true"
  annotations:
    models.ome.io/runtime: "vllm-llama-3-2-90b-vision-instruct-fp8"
    models.ome.io/category: "MEDIUM"
    models.ome.io/experimental: "false"
    models.ome.io/internal: "true"
    models.ome.io/lifecycle-phase: "ACTIVE"
spec:
  disabled: false
  displayName: meta.llama-3.2-90b-vision-instruct-fp8-dynamic
  storage:
    storageUri: oci://n/idqj093njucb/b/model-store/o/meta/llama-3-2-90b-vision-instruct-fp8-dynamic
    path: /raid/models/meta/llama-3-2-90b-vision-instruct-fp8-dynamic
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values:
                  - BM.GPU.H100.8
                  - BM.GPU4.8
                  - BM.GPU.A100-v2.8
  vendor: meta
  version: "1.0.0"
  modelFramework:
    name: transformers
    version: "4.46.0.dev0"
  modelFormat:
    name: safetensors
    version: "1"
  modelArchitecture: MllamaForConditionalGeneration
  modelParameterSize: 90B
  modelCapabilities:
    - "CHAT"
  maxTokens: 131072
  additionalMetadata:
    dacShapeConfigs: |-
      compatibleDACShapes:
        - name: LARGE_GENERIC_V2
          quotaUnit: 1
          default: true
  modelConfiguration:
    {
      "architectures": [
        "MllamaForConditionalGeneration"
      ],
      "quantization_config": {
        "config_groups": {
          "group_0": {
            "input_activations": {
              "actorder": null,
              "block_structure": null,
              "dynamic": true,
              "group_size": null,
              "num_bits": 8,
              "observer": "memoryless",
              "observer_kwargs": {},
              "strategy": "token",
              "symmetric": true,
              "type": "float"
            },
            "output_activations": null,
            "targets": [
              "Linear"
            ],
            "weights": {
              "actorder": null,
              "block_structure": null,
              "dynamic": false,
              "group_size": null,
              "num_bits": 8,
              "observer": "minmax",
              "observer_kwargs": {},
              "strategy": "channel",
              "symmetric": true,
              "type": "float"
            }
          }
        },
        "format": "float-quantized",
        "global_compression_ratio": 1.1987394208518471,
        "ignore": [
          "vision_model.transformer.layers.0.self_attn.q_proj",
          "vision_model.transformer.layers.0.self_attn.k_proj",
          "vision_model.transformer.layers.0.self_attn.v_proj",
          "vision_model.transformer.layers.0.self_attn.o_proj",
          "vision_model.transformer.layers.0.mlp.fc1",
          "vision_model.transformer.layers.0.mlp.fc2",
          "vision_model.transformer.layers.1.self_attn.q_proj",
          "vision_model.transformer.layers.1.self_attn.k_proj",
          "vision_model.transformer.layers.1.self_attn.v_proj",
          "vision_model.transformer.layers.1.self_attn.o_proj",
          "vision_model.transformer.layers.1.mlp.fc1",
          "vision_model.transformer.layers.1.mlp.fc2",
          "vision_model.transformer.layers.2.self_attn.q_proj",
          "vision_model.transformer.layers.2.self_attn.k_proj",
          "vision_model.transformer.layers.2.self_attn.v_proj",
          "vision_model.transformer.layers.2.self_attn.o_proj",
          "vision_model.transformer.layers.2.mlp.fc1",
          "vision_model.transformer.layers.2.mlp.fc2",
          "vision_model.transformer.layers.3.self_attn.q_proj",
          "vision_model.transformer.layers.3.self_attn.k_proj",
          "vision_model.transformer.layers.3.self_attn.v_proj",
          "vision_model.transformer.layers.3.self_attn.o_proj",
          "vision_model.transformer.layers.3.mlp.fc1",
          "vision_model.transformer.layers.3.mlp.fc2",
          "vision_model.transformer.layers.4.self_attn.q_proj",
          "vision_model.transformer.layers.4.self_attn.k_proj",
          "vision_model.transformer.layers.4.self_attn.v_proj",
          "vision_model.transformer.layers.4.self_attn.o_proj",
          "vision_model.transformer.layers.4.mlp.fc1",
          "vision_model.transformer.layers.4.mlp.fc2",
          "vision_model.transformer.layers.5.self_attn.q_proj",
          "vision_model.transformer.layers.5.self_attn.k_proj",
          "vision_model.transformer.layers.5.self_attn.v_proj",
          "vision_model.transformer.layers.5.self_attn.o_proj",
          "vision_model.transformer.layers.5.mlp.fc1",
          "vision_model.transformer.layers.5.mlp.fc2",
          "vision_model.transformer.layers.6.self_attn.q_proj",
          "vision_model.transformer.layers.6.self_attn.k_proj",
          "vision_model.transformer.layers.6.self_attn.v_proj",
          "vision_model.transformer.layers.6.self_attn.o_proj",
          "vision_model.transformer.layers.6.mlp.fc1",
          "vision_model.transformer.layers.6.mlp.fc2",
          "vision_model.transformer.layers.7.self_attn.q_proj",
          "vision_model.transformer.layers.7.self_attn.k_proj",
          "vision_model.transformer.layers.7.self_attn.v_proj",
          "vision_model.transformer.layers.7.self_attn.o_proj",
          "vision_model.transformer.layers.7.mlp.fc1",
          "vision_model.transformer.layers.7.mlp.fc2",
          "vision_model.transformer.layers.8.self_attn.q_proj",
          "vision_model.transformer.layers.8.self_attn.k_proj",
          "vision_model.transformer.layers.8.self_attn.v_proj",
          "vision_model.transformer.layers.8.self_attn.o_proj",
          "vision_model.transformer.layers.8.mlp.fc1",
          "vision_model.transformer.layers.8.mlp.fc2",
          "vision_model.transformer.layers.9.self_attn.q_proj",
          "vision_model.transformer.layers.9.self_attn.k_proj",
          "vision_model.transformer.layers.9.self_attn.v_proj",
          "vision_model.transformer.layers.9.self_attn.o_proj",
          "vision_model.transformer.layers.9.mlp.fc1",
          "vision_model.transformer.layers.9.mlp.fc2",
          "vision_model.transformer.layers.10.self_attn.q_proj",
          "vision_model.transformer.layers.10.self_attn.k_proj",
          "vision_model.transformer.layers.10.self_attn.v_proj",
          "vision_model.transformer.layers.10.self_attn.o_proj",
          "vision_model.transformer.layers.10.mlp.fc1",
          "vision_model.transformer.layers.10.mlp.fc2",
          "vision_model.transformer.layers.11.self_attn.q_proj",
          "vision_model.transformer.layers.11.self_attn.k_proj",
          "vision_model.transformer.layers.11.self_attn.v_proj",
          "vision_model.transformer.layers.11.self_attn.o_proj",
          "vision_model.transformer.layers.11.mlp.fc1",
          "vision_model.transformer.layers.11.mlp.fc2",
          "vision_model.transformer.layers.12.self_attn.q_proj",
          "vision_model.transformer.layers.12.self_attn.k_proj",
          "vision_model.transformer.layers.12.self_attn.v_proj",
          "vision_model.transformer.layers.12.self_attn.o_proj",
          "vision_model.transformer.layers.12.mlp.fc1",
          "vision_model.transformer.layers.12.mlp.fc2",
          "vision_model.transformer.layers.13.self_attn.q_proj",
          "vision_model.transformer.layers.13.self_attn.k_proj",
          "vision_model.transformer.layers.13.self_attn.v_proj",
          "vision_model.transformer.layers.13.self_attn.o_proj",
          "vision_model.transformer.layers.13.mlp.fc1",
          "vision_model.transformer.layers.13.mlp.fc2",
          "vision_model.transformer.layers.14.self_attn.q_proj",
          "vision_model.transformer.layers.14.self_attn.k_proj",
          "vision_model.transformer.layers.14.self_attn.v_proj",
          "vision_model.transformer.layers.14.self_attn.o_proj",
          "vision_model.transformer.layers.14.mlp.fc1",
          "vision_model.transformer.layers.14.mlp.fc2",
          "vision_model.transformer.layers.15.self_attn.q_proj",
          "vision_model.transformer.layers.15.self_attn.k_proj",
          "vision_model.transformer.layers.15.self_attn.v_proj",
          "vision_model.transformer.layers.15.self_attn.o_proj",
          "vision_model.transformer.layers.15.mlp.fc1",
          "vision_model.transformer.layers.15.mlp.fc2",
          "vision_model.transformer.layers.16.self_attn.q_proj",
          "vision_model.transformer.layers.16.self_attn.k_proj",
          "vision_model.transformer.layers.16.self_attn.v_proj",
          "vision_model.transformer.layers.16.self_attn.o_proj",
          "vision_model.transformer.layers.16.mlp.fc1",
          "vision_model.transformer.layers.16.mlp.fc2",
          "vision_model.transformer.layers.17.self_attn.q_proj",
          "vision_model.transformer.layers.17.self_attn.k_proj",
          "vision_model.transformer.layers.17.self_attn.v_proj",
          "vision_model.transformer.layers.17.self_attn.o_proj",
          "vision_model.transformer.layers.17.mlp.fc1",
          "vision_model.transformer.layers.17.mlp.fc2",
          "vision_model.transformer.layers.18.self_attn.q_proj",
          "vision_model.transformer.layers.18.self_attn.k_proj",
          "vision_model.transformer.layers.18.self_attn.v_proj",
          "vision_model.transformer.layers.18.self_attn.o_proj",
          "vision_model.transformer.layers.18.mlp.fc1",
          "vision_model.transformer.layers.18.mlp.fc2",
          "vision_model.transformer.layers.19.self_attn.q_proj",
          "vision_model.transformer.layers.19.self_attn.k_proj",
          "vision_model.transformer.layers.19.self_attn.v_proj",
          "vision_model.transformer.layers.19.self_attn.o_proj",
          "vision_model.transformer.layers.19.mlp.fc1",
          "vision_model.transformer.layers.19.mlp.fc2",
          "vision_model.transformer.layers.20.self_attn.q_proj",
          "vision_model.transformer.layers.20.self_attn.k_proj",
          "vision_model.transformer.layers.20.self_attn.v_proj",
          "vision_model.transformer.layers.20.self_attn.o_proj",
          "vision_model.transformer.layers.20.mlp.fc1",
          "vision_model.transformer.layers.20.mlp.fc2",
          "vision_model.transformer.layers.21.self_attn.q_proj",
          "vision_model.transformer.layers.21.self_attn.k_proj",
          "vision_model.transformer.layers.21.self_attn.v_proj",
          "vision_model.transformer.layers.21.self_attn.o_proj",
          "vision_model.transformer.layers.21.mlp.fc1",
          "vision_model.transformer.layers.21.mlp.fc2",
          "vision_model.transformer.layers.22.self_attn.q_proj",
          "vision_model.transformer.layers.22.self_attn.k_proj",
          "vision_model.transformer.layers.22.self_attn.v_proj",
          "vision_model.transformer.layers.22.self_attn.o_proj",
          "vision_model.transformer.layers.22.mlp.fc1",
          "vision_model.transformer.layers.22.mlp.fc2",
          "vision_model.transformer.layers.23.self_attn.q_proj",
          "vision_model.transformer.layers.23.self_attn.k_proj",
          "vision_model.transformer.layers.23.self_attn.v_proj",
          "vision_model.transformer.layers.23.self_attn.o_proj",
          "vision_model.transformer.layers.23.mlp.fc1",
          "vision_model.transformer.layers.23.mlp.fc2",
          "vision_model.transformer.layers.24.self_attn.q_proj",
          "vision_model.transformer.layers.24.self_attn.k_proj",
          "vision_model.transformer.layers.24.self_attn.v_proj",
          "vision_model.transformer.layers.24.self_attn.o_proj",
          "vision_model.transformer.layers.24.mlp.fc1",
          "vision_model.transformer.layers.24.mlp.fc2",
          "vision_model.transformer.layers.25.self_attn.q_proj",
          "vision_model.transformer.layers.25.self_attn.k_proj",
          "vision_model.transformer.layers.25.self_attn.v_proj",
          "vision_model.transformer.layers.25.self_attn.o_proj",
          "vision_model.transformer.layers.25.mlp.fc1",
          "vision_model.transformer.layers.25.mlp.fc2",
          "vision_model.transformer.layers.26.self_attn.q_proj",
          "vision_model.transformer.layers.26.self_attn.k_proj",
          "vision_model.transformer.layers.26.self_attn.v_proj",
          "vision_model.transformer.layers.26.self_attn.o_proj",
          "vision_model.transformer.layers.26.mlp.fc1",
          "vision_model.transformer.layers.26.mlp.fc2",
          "vision_model.transformer.layers.27.self_attn.q_proj",
          "vision_model.transformer.layers.27.self_attn.k_proj",
          "vision_model.transformer.layers.27.self_attn.v_proj",
          "vision_model.transformer.layers.27.self_attn.o_proj",
          "vision_model.transformer.layers.27.mlp.fc1",
          "vision_model.transformer.layers.27.mlp.fc2",
          "vision_model.transformer.layers.28.self_attn.q_proj",
          "vision_model.transformer.layers.28.self_attn.k_proj",
          "vision_model.transformer.layers.28.self_attn.v_proj",
          "vision_model.transformer.layers.28.self_attn.o_proj",
          "vision_model.transformer.layers.28.mlp.fc1",
          "vision_model.transformer.layers.28.mlp.fc2",
          "vision_model.transformer.layers.29.self_attn.q_proj",
          "vision_model.transformer.layers.29.self_attn.k_proj",
          "vision_model.transformer.layers.29.self_attn.v_proj",
          "vision_model.transformer.layers.29.self_attn.o_proj",
          "vision_model.transformer.layers.29.mlp.fc1",
          "vision_model.transformer.layers.29.mlp.fc2",
          "vision_model.transformer.layers.30.self_attn.q_proj",
          "vision_model.transformer.layers.30.self_attn.k_proj",
          "vision_model.transformer.layers.30.self_attn.v_proj",
          "vision_model.transformer.layers.30.self_attn.o_proj",
          "vision_model.transformer.layers.30.mlp.fc1",
          "vision_model.transformer.layers.30.mlp.fc2",
          "vision_model.transformer.layers.31.self_attn.q_proj",
          "vision_model.transformer.layers.31.self_attn.k_proj",
          "vision_model.transformer.layers.31.self_attn.v_proj",
          "vision_model.transformer.layers.31.self_attn.o_proj",
          "vision_model.transformer.layers.31.mlp.fc1",
          "vision_model.transformer.layers.31.mlp.fc2",
          "vision_model.global_transformer.layers.0.self_attn.q_proj",
          "vision_model.global_transformer.layers.0.self_attn.k_proj",
          "vision_model.global_transformer.layers.0.self_attn.v_proj",
          "vision_model.global_transformer.layers.0.self_attn.o_proj",
          "vision_model.global_transformer.layers.0.mlp.fc1",
          "vision_model.global_transformer.layers.0.mlp.fc2",
          "vision_model.global_transformer.layers.1.self_attn.q_proj",
          "vision_model.global_transformer.layers.1.self_attn.k_proj",
          "vision_model.global_transformer.layers.1.self_attn.v_proj",
          "vision_model.global_transformer.layers.1.self_attn.o_proj",
          "vision_model.global_transformer.layers.1.mlp.fc1",
          "vision_model.global_transformer.layers.1.mlp.fc2",
          "vision_model.global_transformer.layers.2.self_attn.q_proj",
          "vision_model.global_transformer.layers.2.self_attn.k_proj",
          "vision_model.global_transformer.layers.2.self_attn.v_proj",
          "vision_model.global_transformer.layers.2.self_attn.o_proj",
          "vision_model.global_transformer.layers.2.mlp.fc1",
          "vision_model.global_transformer.layers.2.mlp.fc2",
          "vision_model.global_transformer.layers.3.self_attn.q_proj",
          "vision_model.global_transformer.layers.3.self_attn.k_proj",
          "vision_model.global_transformer.layers.3.self_attn.v_proj",
          "vision_model.global_transformer.layers.3.self_attn.o_proj",
          "vision_model.global_transformer.layers.3.mlp.fc1",
          "vision_model.global_transformer.layers.3.mlp.fc2",
          "vision_model.global_transformer.layers.4.self_attn.q_proj",
          "vision_model.global_transformer.layers.4.self_attn.k_proj",
          "vision_model.global_transformer.layers.4.self_attn.v_proj",
          "vision_model.global_transformer.layers.4.self_attn.o_proj",
          "vision_model.global_transformer.layers.4.mlp.fc1",
          "vision_model.global_transformer.layers.4.mlp.fc2",
          "vision_model.global_transformer.layers.5.self_attn.q_proj",
          "vision_model.global_transformer.layers.5.self_attn.k_proj",
          "vision_model.global_transformer.layers.5.self_attn.v_proj",
          "vision_model.global_transformer.layers.5.self_attn.o_proj",
          "vision_model.global_transformer.layers.5.mlp.fc1",
          "vision_model.global_transformer.layers.5.mlp.fc2",
          "vision_model.global_transformer.layers.6.self_attn.q_proj",
          "vision_model.global_transformer.layers.6.self_attn.k_proj",
          "vision_model.global_transformer.layers.6.self_attn.v_proj",
          "vision_model.global_transformer.layers.6.self_attn.o_proj",
          "vision_model.global_transformer.layers.6.mlp.fc1",
          "vision_model.global_transformer.layers.6.mlp.fc2",
          "vision_model.global_transformer.layers.7.self_attn.q_proj",
          "vision_model.global_transformer.layers.7.self_attn.k_proj",
          "vision_model.global_transformer.layers.7.self_attn.v_proj",
          "vision_model.global_transformer.layers.7.self_attn.o_proj",
          "vision_model.global_transformer.layers.7.mlp.fc1",
          "vision_model.global_transformer.layers.7.mlp.fc2",
          "language_model.lm_head",
          "multi_modal_projector"
        ],
        "kv_cache_scheme": null,
        "quant_method": "compressed-tensors",
        "quantization_status": "compressed"
      },
      "image_token_index": 128256,
      "model_type": "mllama",
      "text_config": {
        "_name_or_path": "",
        "add_cross_attention": false,
        "architectures": null,
        "bad_words_ids": null,
        "begin_suppress_tokens": null,
        "bos_token_id": 128000,
        "chunk_size_feed_forward": 0,
        "cross_attention_hidden_size": null,
        "cross_attention_layers": [
          3,
          8,
          13,
          18,
          23,
          28,
          33,
          38,
          43,
          48,
          53,
          58,
          63,
          68,
          73,
          78,
          83,
          88,
          93,
          98
        ],
        "decoder_start_token_id": null,
        "diversity_penalty": 0.0,
        "do_sample": false,
        "dropout": 0,
        "early_stopping": false,
        "encoder_no_repeat_ngram_size": 0,
        "eos_token_id": [
          128001,
          128008,
          128009
        ],
        "exponential_decay_length_penalty": null,
        "finetuning_task": null,
        "forced_bos_token_id": null,
        "forced_eos_token_id": null,
        "hidden_act": "silu",
        "hidden_size": 8192,
        "id2label": {
          "0": "LABEL_0",
          "1": "LABEL_1"
        },
        "initializer_range": 0.02,
        "intermediate_size": 28672,
        "is_decoder": false,
        "is_encoder_decoder": false,
        "label2id": {
          "LABEL_0": 0,
          "LABEL_1": 1
        },
        "length_penalty": 1.0,
        "max_length": 20,
        "max_position_embeddings": 131072,
        "min_length": 0,
        "model_type": "mllama_text_model",
        "no_repeat_ngram_size": 0,
        "num_attention_heads": 64,
        "num_beam_groups": 1,
        "num_beams": 1,
        "num_hidden_layers": 100,
        "num_key_value_heads": 8,
        "num_return_sequences": 1,
        "output_attentions": false,
        "output_hidden_states": false,
        "output_scores": false,
        "pad_token_id": 128004,
        "prefix": null,
        "problem_type": null,
        "pruned_heads": {},
        "remove_invalid_values": false,
        "repetition_penalty": 1.0,
        "return_dict": true,
        "return_dict_in_generate": false,
        "rms_norm_eps": 1e-05,
        "rope_scaling": {
          "factor": 8.0,
          "high_freq_factor": 4.0,
          "low_freq_factor": 1.0,
          "original_max_position_embeddings": 8192,
          "rope_type": "llama3"
        },
        "rope_theta": 500000.0,
        "sep_token_id": null,
        "suppress_tokens": null,
        "task_specific_params": null,
        "temperature": 1.0,
        "tf_legacy_loss": false,
        "tie_encoder_decoder": false,
        "tie_word_embeddings": false,
        "tokenizer_class": null,
        "top_k": 50,
        "top_p": 1.0,
        "torch_dtype": "bfloat16",
        "torchscript": false,
        "typical_p": 1.0,
        "use_bfloat16": false,
        "use_cache": true,
        "vocab_size": 128256
      },
      "torch_dtype": "bfloat16",
      "transformers_version": "4.46.0.dev0",
      "vision_config": {
        "_name_or_path": "",
        "add_cross_attention": false,
        "architectures": null,
        "attention_heads": 16,
        "bad_words_ids": null,
        "begin_suppress_tokens": null,
        "bos_token_id": null,
        "chunk_size_feed_forward": 0,
        "cross_attention_hidden_size": null,
        "decoder_start_token_id": null,
        "diversity_penalty": 0.0,
        "do_sample": false,
        "early_stopping": false,
        "encoder_no_repeat_ngram_size": 0,
        "eos_token_id": null,
        "exponential_decay_length_penalty": null,
        "finetuning_task": null,
        "forced_bos_token_id": null,
        "forced_eos_token_id": null,
        "hidden_act": "gelu",
        "hidden_size": 1280,
        "id2label": {
          "0": "LABEL_0",
          "1": "LABEL_1"
        },
        "image_size": 560,
        "initializer_range": 0.02,
        "intermediate_layers_indices": [
          3,
          7,
          15,
          23,
          30
        ],
        "intermediate_size": 5120,
        "is_decoder": false,
        "is_encoder_decoder": false,
        "label2id": {
          "LABEL_0": 0,
          "LABEL_1": 1
        },
        "length_penalty": 1.0,
        "max_length": 20,
        "max_num_tiles": 4,
        "min_length": 0,
        "model_type": "mllama_vision_model",
        "no_repeat_ngram_size": 0,
        "norm_eps": 1e-05,
        "num_beam_groups": 1,
        "num_beams": 1,
        "num_channels": 3,
        "num_global_layers": 8,
        "num_hidden_layers": 32,
        "num_return_sequences": 1,
        "output_attentions": false,
        "output_hidden_states": false,
        "output_scores": false,
        "pad_token_id": null,
        "patch_size": 14,
        "prefix": null,
        "problem_type": null,
        "pruned_heads": {},
        "remove_invalid_values": false,
        "repetition_penalty": 1.0,
        "return_dict": true,
        "return_dict_in_generate": false,
        "sep_token_id": null,
        "supported_aspect_ratios": [
          [
            1,
            1
          ],
          [
            1,
            2
          ],
          [
            1,
            3
          ],
          [
            1,
            4
          ],
          [
            2,
            1
          ],
          [
            2,
            2
          ],
          [
            3,
            1
          ],
          [
            4,
            1
          ]
        ],
        "suppress_tokens": null,
        "task_specific_params": null,
        "temperature": 1.0,
        "tf_legacy_loss": false,
        "tie_encoder_decoder": false,
        "tie_word_embeddings": true,
        "tokenizer_class": null,
        "top_k": 50,
        "top_p": 1.0,
        "torch_dtype": "bfloat16",
        "torchscript": false,
        "typical_p": 1.0,
        "use_bfloat16": false,
        "vision_output_dim": 7680
      }
    }