apiVersion: ome.io/v1beta1
kind: ClusterBaseModel
metadata:
  name: llama-4-maverick-17b-128e-instruct-fp8
spec:
  vendor: meta
  disabled: false
  displayName: meta.llama-4-maverick-17b-128e-instruct-fp8
  version: "1.0.0"
  storage:
    storageUri: oci://n/idqj093njucb/b/model-store/o/meta/llama-4-maverick-17b-128e-instruct-fp8
    path: /raid/models/meta/llama-4-maverick-17b-128e-instruct-fp8
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values:
                  - BM.GPU.H100.8
                  - BM.GPU4.8
                  - BM.GPU.A100-v2.8