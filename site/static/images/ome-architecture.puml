@startuml OME Architecture
!theme plain
skinparam backgroundColor #FEFEFE
skinparam boxPadding 10
skinparam defaultFontSize 12
skinparam ArrowColor #4279f4
skinparam rectangleBackgroundColor #f8f9fa
skinparam componentBackgroundColor #e3f2fd
skinparam packageBackgroundColor #fff3cd
skinparam noteBackgroundColor #d1ecf1

title OME (Operator for Machine learning Endpoints) Architecture

' Define the layers
package "User/Client Layer" #e8f5e9 {
  actor "User/Application" as user
  component "kubectl/API" as kubectl
  component "Benchmark Client" as bench_client
}

package "Kubernetes API Layer" #e3f2fd {
  package "Custom Resources (ome.io/v1beta1)" #bbdefb {
    entity "InferenceService" as isvc <<CRD>> {
      + Engine Component
      + Decoder Component
      + Router Component
      + Model Reference
      + Runtime Reference
    }
    
    entity "BaseModel" as model <<CRD>> {
      + Model Source
      + Format/Architecture
      + Quantization
      + Capabilities
    }
    
    entity "ClusterBaseModel" as cmodel <<CRD>> {
      + Cluster-wide Model
    }
    
    entity "ServingRuntime" as runtime <<CRD>> {
      + Container Specs
      + Supported Formats
      + Resource Requirements
    }
    
    entity "ClusterServingRuntime" as cruntime <<CRD>> {
      + Cluster-wide Runtime
    }
    
    entity "BenchmarkJob" as bench <<CRD>> {
      + Traffic Scenarios
      + Concurrency Settings
      + Result Storage
    }
    
    entity "FineTunedWeight" as ftw <<CRD>> {
      + LoRA Adapters
      + Base Model Ref
    }
  }
  
  package "Admission Webhooks" #fff3cd {
    component "Validating Webhook" as vwebhook
    component "Mutating Webhook" as mwebhook
    component "Pod Mutator" as podmutator
  }
}

package "Control Plane" #f3e5f5 {
  component "OME Manager" as manager <<Controller>> {
    + InferenceService Controller
    + BaseModel Controller
    + BenchmarkJob Controller
    + ServingRuntime Controller
  }
  
  package "Reconcilers" #e1bee7 {
    component "Deployment Reconciler" as dep_rec
    component "Service Reconciler" as svc_rec
    component "Ingress Reconciler" as ing_rec
    component "HPA/KEDA Reconciler" as scale_rec
    component "Multi-Node Reconciler" as multi_rec
    component "Model Config Reconciler" as model_rec
    component "RBAC Reconciler" as rbac_rec
  }
}

package "Data Plane" #fff9c4 {
  package "Node Agents" #ffecb3 {
    component "Model Agent" as model_agent <<DaemonSet>> {
      + Model Download
      + Model Parsing
      + Node Labeling
      + Cache Management
    }
    
    component "OME Agent" as ome_agent <<Pod>> {
      + Enigma (Encryption)
      + HF Download
      + Replica Management
      + Serving Management
      + LoRA Adapter Handling
    }
    
    component "Multinode Prober" as prober <<Pod>> {
      + Health Checking
      + Multi-node Coordination
    }
  }
  
  package "Inference Workloads" #c8e6c9 {
    component "Engine Pod(s)" as engine {
      + Model Serving
      + Request Processing
      + Leader/Worker Mode
    }
    
    component "Decoder Pod(s)" as decoder {
      + Token Decoding
      + Prefill-Decode Split
      + Leader/Worker Mode
    }
    
    component "Router Pod" as router {
      + Request Routing
      + Load Balancing
    }
  }
  
  package "Benchmark Workloads" #d7ccc8 {
    component "Benchmark Pod" as bench_pod {
      + genai-bench
      + Traffic Generation
      + Metrics Collection
    }
  }
}

package "Storage Layer" #e0f2f1 {
  database "Model Storage" as storage {
    + OCI Object Storage
    + PVC
    + HuggingFace Hub
    + Vendor Storage
  }
  
  database "Results Storage" as results {
    + Benchmark Results
    + Metrics/Logs
  }
}

package "External Integrations" #fce4ec {
  component "KEDA" as keda <<External>>
  component "Gateway API" as gateway <<External>>
  component "Istio" as istio <<External>>
  component "LeaderWorkerSet" as lws <<External>>
  component "Ray" as ray <<External>>
  component "Kueue" as kueue <<External>>
  component "Prometheus" as prom <<External>>
}

package "Inference Runtimes" #e8eaf6 {
  component "SGLang" as sglang <<Runtime>>
  component "vLLM" as vllm <<Runtime>>
  component "TensorRT-LLM" as trtllm <<Runtime>>
  component "Triton" as triton <<Runtime>>
}

' Define relationships
user --> kubectl : API Requests
user --> bench_client : Benchmark Tests

kubectl --> isvc : Create/Update
kubectl --> model : Create/Update
kubectl --> runtime : Create/Update
kubectl --> bench : Create

isvc --> model : References
isvc --> runtime : References
isvc --> ftw : Optional Reference

vwebhook --> isvc : Validates
mwebhook --> isvc : Mutates
podmutator --> engine : Injects Sidecars

manager --> isvc : Watches/Reconciles
manager --> model : Watches/Reconciles
manager --> runtime : Watches/Reconciles
manager --> bench : Watches/Reconciles

manager --> dep_rec : Invokes
manager --> svc_rec : Invokes
manager --> ing_rec : Invokes
manager --> scale_rec : Invokes
manager --> multi_rec : Invokes
manager --> model_rec : Invokes
manager --> rbac_rec : Invokes

dep_rec --> engine : Creates/Updates
dep_rec --> decoder : Creates/Updates
dep_rec --> router : Creates/Updates
svc_rec --> engine : Exposes
ing_rec --> gateway : Configures
ing_rec --> istio : Configures
scale_rec --> keda : Configures
multi_rec --> lws : Creates
multi_rec --> ray : Creates

model_agent --> storage : Downloads Models
model_agent --> model : Updates Status
ome_agent --> engine : Configures
ome_agent --> storage : Manages Models

engine --> sglang : Uses
engine --> vllm : Uses
engine --> trtllm : Uses
engine --> triton : Uses

bench_pod --> engine : Tests
bench_pod --> results : Stores Results
bench --> bench_pod : Creates

prober --> engine : Health Checks
engine --> decoder : Communicates
decoder --> router : Routes Responses

manager --> kueue : Job Scheduling
engine --> prom : Exports Metrics

note right of isvc
  InferenceService is the main
  resource that orchestrates
  model deployment
end note

note bottom of model_agent
  Model Agent runs on every
  node as a DaemonSet
end note

note right of engine
  Supports multiple deployment
  patterns including prefill-decode
  disaggregation
end note

@enduml