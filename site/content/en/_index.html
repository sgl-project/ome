+++
title = "OME"
linkTitle = "OME"
description = "OME is a cloud-native job queueing system for batch, HPC, AI/ML, and similar applications in a Kubernetes cluster"
+++

{{< blocks/cover title="Welcome to OME" image_anchor="top" height="full" color="orange" >}}
<div class="mx-auto">
	<a class="btn btn-lg btn-primary mr-3 mb-4" href="/docs/">
		Read the docs <i class="fas fa-arrow-alt-circle-right ml-2"></i>
	</a>
	<a class="btn btn-lg btn-secondary mr-3 mb-4" href="https://github.com/sgl-project/ome">
		GitHub <i class="fab fa-github ml-2 "></i>
	</a>
	<p class="lead mt-5">Open Model Engine on OKE</p>
	{{< blocks/link-down color="info" id="description" >}}
</div>
{{< /blocks/cover >}}

<div id="description" ></div>

{{% blocks/lead color="primary"%}}
<h1  class="text-center">
	OME is a standard operator for managing the lifecycle of LLM models, serving, training, and dedicated AI clusters in an OKE cluster. It is designed to be a generic operator that can be used to manage the lifecycle of any AI/ML workload in a Kubernetes cluster running on OCI.
</h1>
{{% /blocks/lead %}}

{{% blocks/lead color="secondary" %}}
<h1 class="text-center">
	OME supports both serving and training for Hugging Face-compatible models and Cohere models in single-node and multi-node configurations. OME ensures high availability for both serving and training in both modes. For multi-node deployments, OME supports custom metrics-based scaling and scale-to-zero functionality.
</h1>
{{% /blocks/lead %}}

{{% blocks/lead color="dark" %}}
<h1 class="text-center">
	Leverage OME to build a multi-tenant AI/ML workload management service with resource quotas and a hierarchical structure for sharing resources across teams. OME provides a unified interface for managing AI/ML workloads across multiple teams and projects.
</h1>
{{% /blocks/lead %}}