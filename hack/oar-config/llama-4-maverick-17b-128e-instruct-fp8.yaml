# DO NOT EDIT, UPDATE, OR APPLY this file to upstream cluster unless you have consulted with Simo Lin
apiVersion: ome.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    ome.io/deploymentMode: RawDeployment
    ome.io/service-type: "LoadBalancer"
    ome.io/load-balancer-ip: "147.154.178.181"
  name: llama-4-maverick-17b-128e-instruct-fp8
  namespace: aor-evaluator-ns
spec:
  predictor:
    maxReplicas: 1
    minReplicas: 1
    model:
      baseModel: llama-4-maverick-17b-128e-instruct-fp8
      name: ''
      protocolVersion: openAI
      resources: {}
      runtime: vllm-llama-4-maverick-17b-128e-instruct-fp8
    workerSpec: {}