# DO NOT EDIT, UPDATE, OR APPLY this file to upstream cluster unless you have consulted with Simo Lin
apiVersion: ome.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    ome.io/deploymentMode: RawDeployment
    ome.io/service-type: "LoadBalancer"
    ome.io/load-balancer-ip: "147.154.182.82"
  name: llama-3-3-nemotron-super-49b-v1
  namespace: aor-evaluator-ns
spec:
  predictor:
    maxReplicas: 1
    minReplicas: 1
    model:
      baseModel: llama-3-3-nemotron-super-49b-v1
      name: ''
      protocolVersion: openAI
      resources: {}
      runtime: vllm-llama-3-3-nemotron-super-49b-v1
    workerSpec: {}